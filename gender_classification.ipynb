{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UKreC1p_fDv5"
      },
      "source": [
        "Q1. Gender Classification\n",
        "\n",
        "Use train_test_split(random_state = 42,test_size = 0.2)\n",
        "\n",
        "Do some EDA (countplots, show images, find missing values etc.)\n",
        "\n",
        "a. Use Base SVM(LinearSVC) model.\n",
        "\n",
        "b. Create a CNN model with 3 Conv2D layers, 3 Maxpooling2D layers, any extra layers necessary.\n",
        "\n",
        "c. Get atleast 90% test accuracy using the above CNN model.\n",
        "\n",
        "df: https://www.kaggle.com/dfsets/cashutosh/gender-classification-dfset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hBh4zei2fAmy"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
        "from sklearn.metrics import mean_squared_error, accuracy_score\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import LinearSVC\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from PIL import Image\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import cv2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OY8Tnr5cUYIR"
      },
      "outputs": [],
      "source": [
        "male = \"./Training/male/\"\n",
        "female = \"./Training/female/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MRg7SwhkUYIV"
      },
      "outputs": [],
      "source": [
        "male_files = [os.path.join(male, file) for file in os.listdir(male)]\n",
        "female_files = [os.path.join(female, file) for file in os.listdir(female)]\n",
        "\n",
        "# into dataframe\n",
        "df = pd.DataFrame({\"image_path\": male_files + female_files, \"gender\": [\"male\"] * len(male_files) + [\"female\"] * len(female_files)})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r2pLWb7-UYIY",
        "outputId": "9a9d1ee5-3e65-4980-cd99-80fc830dbbc1"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_path</th>\n",
              "      <th>gender</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>./Training/male/090544.jpg.jpg</td>\n",
              "      <td>male</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>./Training/male/090545.jpg.jpg</td>\n",
              "      <td>male</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>./Training/male/090548.jpg.jpg</td>\n",
              "      <td>male</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>./Training/male/090550.jpg.jpg</td>\n",
              "      <td>male</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>./Training/male/090553.jpg.jpg</td>\n",
              "      <td>male</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47004</th>\n",
              "      <td>./Training/female/202592.jpg.jpg</td>\n",
              "      <td>female</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47005</th>\n",
              "      <td>./Training/female/202593.jpg.jpg</td>\n",
              "      <td>female</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47006</th>\n",
              "      <td>./Training/female/202594.jpg.jpg</td>\n",
              "      <td>female</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47007</th>\n",
              "      <td>./Training/female/202598.jpg.jpg</td>\n",
              "      <td>female</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47008</th>\n",
              "      <td>./Training/female/202599.jpg.jpg</td>\n",
              "      <td>female</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>47009 rows Ã— 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                             image_path  gender\n",
              "0        ./Training/male/090544.jpg.jpg    male\n",
              "1        ./Training/male/090545.jpg.jpg    male\n",
              "2        ./Training/male/090548.jpg.jpg    male\n",
              "3        ./Training/male/090550.jpg.jpg    male\n",
              "4        ./Training/male/090553.jpg.jpg    male\n",
              "...                                 ...     ...\n",
              "47004  ./Training/female/202592.jpg.jpg  female\n",
              "47005  ./Training/female/202593.jpg.jpg  female\n",
              "47006  ./Training/female/202594.jpg.jpg  female\n",
              "47007  ./Training/female/202598.jpg.jpg  female\n",
              "47008  ./Training/female/202599.jpg.jpg  female\n",
              "\n",
              "[47009 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# print(df.info())\n",
        "\n",
        "display(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dJ0bFTVqUYIj"
      },
      "outputs": [],
      "source": [
        "# seting the dataset\n",
        "X = df['image_path']\n",
        "y = df['gender']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IBYD3PJBUYIp",
        "outputId": "c3c2423f-a9d4-4fa2-966c-cc69176e0d30"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\hp2023\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
            "  warnings.warn(\n",
            "c:\\Users\\hp2023\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LinearSVC Accuracy: 0.8114231014677729\n"
          ]
        }
      ],
      "source": [
        "# Load images and convert them to grayscale\n",
        "image_size = (48, 48)\n",
        "X_train_images = X_train.apply(lambda x: cv2.resize(cv2.cvtColor(cv2.imread(x), cv2.COLOR_BGR2GRAY), image_size))\n",
        "X_test_images = X_test.apply(lambda x: cv2.resize(cv2.cvtColor(cv2.imread(x), cv2.COLOR_BGR2GRAY), image_size))\n",
        "\n",
        "# Flatten images\n",
        "X_train_flat = np.array([img.flatten() for img in X_train_images])\n",
        "X_test_flat = np.array([img.flatten() for img in X_test_images])\n",
        "\n",
        "# Initialize and train LinearSVC\n",
        "svm_model = LinearSVC(random_state=42)\n",
        "svm_model.fit(X_train_flat, y_train)\n",
        "\n",
        "# Predict and evaluate\n",
        "svm_pred = svm_model.predict(X_test_flat)\n",
        "svm_accuracy = accuracy_score(y_test, svm_pred)\n",
        "print(\"LinearSVC Accuracy:\", svm_accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GdClALW2UYIu",
        "outputId": "cb159677-dca6-4308-e5e1-c3689955c57a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1058/1058 [==============================] - 141s 126ms/step - loss: 0.2549 - accuracy: 0.8942 - val_loss: 0.1714 - val_accuracy: 0.9378\n",
            "Epoch 2/10\n",
            "1058/1058 [==============================] - 126s 119ms/step - loss: 0.1556 - accuracy: 0.9435 - val_loss: 0.1599 - val_accuracy: 0.9476\n",
            "Epoch 3/10\n",
            "1058/1058 [==============================] - 130s 123ms/step - loss: 0.1338 - accuracy: 0.9501 - val_loss: 0.1448 - val_accuracy: 0.9431\n",
            "Epoch 4/10\n",
            "1058/1058 [==============================] - 127s 120ms/step - loss: 0.1174 - accuracy: 0.9573 - val_loss: 0.1335 - val_accuracy: 0.9489\n",
            "Epoch 5/10\n",
            "1058/1058 [==============================] - 133s 125ms/step - loss: 0.1104 - accuracy: 0.9588 - val_loss: 0.1183 - val_accuracy: 0.9614\n",
            "Epoch 6/10\n",
            "1058/1058 [==============================] - 130s 122ms/step - loss: 0.0985 - accuracy: 0.9648 - val_loss: 0.1195 - val_accuracy: 0.9599\n",
            "Epoch 7/10\n",
            "1058/1058 [==============================] - 129s 122ms/step - loss: 0.0933 - accuracy: 0.9666 - val_loss: 0.1226 - val_accuracy: 0.9585\n",
            "Epoch 8/10\n",
            "1058/1058 [==============================] - 126s 119ms/step - loss: 0.0834 - accuracy: 0.9711 - val_loss: 0.1216 - val_accuracy: 0.9593\n",
            "Epoch 9/10\n",
            "1058/1058 [==============================] - 127s 120ms/step - loss: 0.0762 - accuracy: 0.9726 - val_loss: 0.1439 - val_accuracy: 0.9476\n",
            "Epoch 10/10\n",
            "1058/1058 [==============================] - 128s 121ms/step - loss: 0.0719 - accuracy: 0.9736 - val_loss: 0.1345 - val_accuracy: 0.9612\n",
            "294/294 [==============================] - 12s 39ms/step - loss: 0.1404 - accuracy: 0.9578\n",
            "CNN Test Accuracy: 0.9577749371528625\n"
          ]
        }
      ],
      "source": [
        "# Convert gender labels to numerical format\n",
        "gender_mapping = {\"male\": 0, \"female\": 1}\n",
        "y_train_numeric = y_train.map(gender_mapping)\n",
        "y_test_numeric = y_test.map(gender_mapping)\n",
        "\n",
        "# Load images and preprocess them for CNN\n",
        "X_train_cnn = X_train.apply(lambda x: np.array(Image.open(x).resize((48, 48))).astype('float32') / 255.0)\n",
        "X_test_cnn = X_test.apply(lambda x: np.array(Image.open(x).resize((48, 48))).astype('float32') / 255.0)\n",
        "\n",
        "# Build CNN model\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(48, 48, 3)),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Conv2D(128, (3, 3), activation='relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Flatten(),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')  # Binary classification\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(np.array(X_train_cnn.tolist()), y_train_numeric, epochs=10, batch_size=32, validation_split=0.1)\n",
        "\n",
        "# Evaluate the model\n",
        "cnn_loss, cnn_accuracy = model.evaluate(np.array(X_test_cnn.tolist()), y_test_numeric)\n",
        "print(\"CNN Test Accuracy:\", cnn_accuracy)\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}